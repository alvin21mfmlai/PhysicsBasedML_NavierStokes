{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Python Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import scipy.io\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "from itertools import product, combinations\n",
    "from plotting import newfig, savefig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Physics Involved for NAVIER STOKES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navier-Stokes equation\n",
    "\n",
    "Given a two-dimensional velocity field, \n",
    "\n",
    "$$ {\\bf V}(x, y; t)  =  ( u(x, y; t), v(x, y; t) )  \\; \\;,  $$\n",
    "its components satisfy the following equations\n",
    "\n",
    "$$ u_t + \\lambda_1 ( u u_x + v u_y ) = -p_x + \\lambda_2 ( u_{xx} + u_{yy}) $$\n",
    "$$ v_t + \\lambda_1 ( u v_x + v v_y ) = -p_y+ \\lambda_2 ( v_{xx} + v_{yy}) $$\n",
    "with $ p = p(x, y; t)$ being the pressure. The parameters $\\lambda_1 $ and $\\lambda_2$ are unknown.\n",
    "\n",
    "We are interested in learning the parameters $\\{ \\lambda \\} $ as well as the pressure $ p(x, y; t)$.\n",
    "\n",
    "Solutions are searched in a set satisfying continuity equation $ \\nabla \\cdot {\\bf V}(x, y; t) = 0 $, \n",
    "\n",
    "$$ u_x + v_y = 0  \\; \\;.$$\n",
    "\n",
    "Defining a latent function $ \\psi = \\psi(x, y; t) $ such that (how crucial is the use of $\\psi$?):\n",
    "$$ u = \\psi_y   \\;, $$ \n",
    "$$ v = - \\psi_x  \\;, $$ \n",
    "the continuity equation is satistied. Given a set ${\\cal S}$ of (noisy) measurements of the velocity field, \n",
    "\n",
    "$$    {\\cal S} = \\{ t^{(j)}, x^{(j)}, y^{(j)} , u^{(j)}, v^{(j)}   \\}_{j=1}^{N}  \\;, $$\n",
    "we define\n",
    "\n",
    "$$ f(x, y; t) \\equiv u_t + \\lambda_1 ( u u_x + v u_y )  + p_x - \\lambda_2 ( u_{xx} + u_{yy}) \\;,$$    \n",
    "$$  g(x, y; t) \\equiv v_t + \\lambda_1 ( u v_x + v v_y ) + p_y - \\lambda_2 ( v_{xx} + v_{yy})  \\;,$$\n",
    "and proceed by jointly approximating\n",
    "\n",
    "$$ \\left[   \\psi(x, y; t) ;  p(x, y; t)  \\right]  \\;, $$\n",
    "using a single neural network with two outputs.\n",
    "\n",
    "The prior assumption is taking into account in another neural network (PINN) with two outputs:\n",
    "\n",
    "$$ \\left[   f(x, y; t) ;  g(x, y; t)  \\right]  \\;. $$\n",
    "\n",
    "The parameters $\\{ \\lambda \\} $ operate as well as the parameters of the neural networks:\n",
    "\n",
    "\n",
    "$$ \\left[   \\psi(x, y; t) ;  p(x, y; t)  \\right]  \\;, $$\n",
    "$$ \\left[   f(x, y; t) ;  g(x, y; t)  \\right]  \\;, $$\n",
    "that can be trained using a mean squared error loss:\n",
    "\n",
    "$$  MSE \\equiv \\frac{1}{N} \\sum_{j=1}^{N} \\left[  \\left( u( x^{(j)}, y^{(j)}, t^{(j)}) - u^{(j)} \\right)^2 + \\left( v( x^{(j)}, y^{(j)}, t^{(j)}) - v^{(j)} \\right)^2  \\right]  + \\frac{1}{N} \\sum_{j=1}^{N} \\left[   |  u( x^{(j)}, y^{(j)}, t^{(j)}) |^2 +  |g( x^{(j)}, y^{(j)}, t^{(j)})|^2       \\right]     $$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. User-defined Classes and Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x, y, t, u, v, layers):\n",
    "        \n",
    "        X = np.concatenate([x, y, t], 1)\n",
    "        \n",
    "        self.lb = X.min(0) ## LOWER BOUNDS FOR MODEL INPUTS, INPUTS CONTAIN X, Y & Time (t) ##\n",
    "        self.ub = X.max(0) ## UPPER BOUNDS FOR MODEL INPUTS, INPUTS CONTAIN X, Y & Time (t) ##\n",
    "                \n",
    "        self.X = X\n",
    "        \n",
    "        self.x = X[:,0:1]\n",
    "        self.y = X[:,1:2]\n",
    "        self.t = X[:,2:3]\n",
    "        \n",
    "        self.u = u\n",
    "        self.v = v\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "        # Initialize NN\n",
    "        self.weights, self.biases = self.initialize_NN(layers)        \n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.lambda_1 = tf.Variable([0.0], dtype=tf.float32) ## UNKNOWN LAMBDA 1 Parameter ##\n",
    "        self.lambda_2 = tf.Variable([0.0], dtype=tf.float32) ## UNKNOWN LAMBDA 2 Parameter ##\n",
    "        \n",
    "        # tf placeholders and graph\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        \n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
    "        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]])\n",
    "        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n",
    "        \n",
    "        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
    "        self.v_tf = tf.placeholder(tf.float32, shape=[None, self.v.shape[1]])\n",
    "        \n",
    "        self.u_pred, self.v_pred, self.p_pred, self.f_u_pred, self.f_v_pred = self.net_NS(self.x_tf, self.y_tf, self.t_tf)\n",
    "        \n",
    "        self.loss = tf.reduce_sum(tf.square(self.u_tf - self.u_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.v_tf - self.v_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_u_pred)) + \\\n",
    "                    tf.reduce_sum(tf.square(self.f_v_pred))\n",
    "                    \n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 50000,\n",
    "                                                                           'maxfun': 50000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})        \n",
    "        \n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)                    \n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]]) ## USING XAVIER INITIALIZATION (SEE FUNCTION BELOW) TO ##\n",
    "                                                                ## INITIALIZE RANDOM WEIGHTS ##\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32) ## INITIALIZE RANDOM BIASES ##\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        \n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            #b = biases[l]\n",
    "            #H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "            H = tf.tanh(tf.matmul(H, W))\n",
    "        W = weights[-1]\n",
    "        #b = np.float64(biases[-1])\n",
    "        #Y = tf.add(tf.matmul(H, W), b)\n",
    "        Y = tf.matmul(H, W)\n",
    "        return Y\n",
    "        \n",
    "    def net_NS(self, x, y, t):\n",
    "        lambda_1 = self.lambda_1\n",
    "        lambda_2 = self.lambda_2\n",
    "        \n",
    "        psi_and_p = self.neural_net(tf.concat([x,y,t], 1), self.weights, self.biases) ## NEURAL NETWORK TO ESTIMATE\n",
    "                                                                                      ## PRESSURES AND LATENT FUNCTION ##\n",
    "        psi = psi_and_p[:,0:1]\n",
    "        p = psi_and_p[:,1:2]\n",
    "        \n",
    "        u = tf.gradients(psi, y)[0] ## LATENT FUNCTION TO PREDICT U-VELOCITY ##\n",
    "        v = -tf.gradients(psi, x)[0] ## LATENT FUNCTION TO PREDICT V-VELOCITY ##\n",
    "        \n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_y = tf.gradients(u, y)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        u_yy = tf.gradients(u_y, y)[0]\n",
    "        \n",
    "        v_t = tf.gradients(v, t)[0]\n",
    "        v_x = tf.gradients(v, x)[0]\n",
    "        v_y = tf.gradients(v, y)[0]\n",
    "        v_xx = tf.gradients(v_x, x)[0]\n",
    "        v_yy = tf.gradients(v_y, y)[0]\n",
    "        \n",
    "        p_x = tf.gradients(p, x)[0]\n",
    "        p_y = tf.gradients(p, y)[0]\n",
    "\n",
    "        f_u = u_t + lambda_1*(u*u_x + v*u_y) + p_x - lambda_2*(u_xx + u_yy)  ## FUNCTION TO PREDICT U-VELOCITY ##\n",
    "        f_v = v_t + lambda_1*(u*v_x + v*v_y) + p_y - lambda_2*(v_xx + v_yy)  ## FUNCTION TO PREDICT V-VELOCITY ##\n",
    "        \n",
    "        return u, v, p, f_u, f_v\n",
    "    \n",
    "    def callback(self, loss, lambda_1, lambda_2):\n",
    "        print('Loss: %.3e, l1: %.3f, l2: %.5f' % (loss, lambda_1, lambda_2))\n",
    "      \n",
    "    def train(self, nIter): \n",
    "\n",
    "        tf_dict = {self.x_tf: self.x, self.y_tf: self.y, self.t_tf: self.t,\n",
    "                   self.u_tf: self.u, self.v_tf: self.v}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            \n",
    "            # Print\n",
    "            if it % 10 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                loss_value = self.sess.run(self.loss, tf_dict)\n",
    "                lambda_1_value = self.sess.run(self.lambda_1)\n",
    "                lambda_2_value = self.sess.run(self.lambda_2)\n",
    "                print('It: %d, Loss: %.3e, l1: %.3f, l2: %.5f, Time: %.2f' % \n",
    "                      (it, loss_value, lambda_1_value, lambda_2_value, elapsed))\n",
    "                start_time = time.time()\n",
    "            \n",
    "        self.optimizer.minimize(self.sess,\n",
    "                                feed_dict = tf_dict,\n",
    "                                fetches = [self.loss, self.lambda_1, self.lambda_2],\n",
    "                                loss_callback = self.callback)\n",
    "            \n",
    "    \n",
    "    def predict(self, x_star, y_star, t_star):\n",
    "        \n",
    "        tf_dict = {self.x_tf: x_star, self.y_tf: y_star, self.t_tf: t_star}\n",
    "        \n",
    "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
    "        v_star = self.sess.run(self.v_pred, tf_dict)\n",
    "        p_star = self.sess.run(self.p_pred, tf_dict)\n",
    "        \n",
    "        return u_star, v_star, p_star"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
